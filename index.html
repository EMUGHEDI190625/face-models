<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Secure Face Recognition</title>
  <!-- <script src="./face-api.min.js"></script> -->
   <script src="https://cdn.jsdelivr.net/npm/face-api.js/dist/face-api.min.js"></script>
  <style>
    body { text-align:center; font-family:Arial; background:#fafafa; }
    video { border:2px solid #ccc; border-radius:10px; width:320px; }
  </style>
</head>
<body>
  <h3>Authorized Face Recognition</h3>
  <p id="status">⏳ Loading models...</p>
  <button id="startBtn" disabled>Start Camera</button><br><br>
  <video id="video" autoplay muted></video>

  <script>
  const video = document.getElementById('video');
  const statusEl = document.getElementById('status');
  const startBtn = document.getElementById('startBtn');
  let faceMatcher;

  async function loadModels() {
    await Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri('./models'),
      faceapi.nets.faceLandmark68Net.loadFromUri('./models'),
      faceapi.nets.faceRecognitionNet.loadFromUri('./models')
    ]);

    const response = await fetch('./knownFaces.json');
    const knownData = await response.json();
    const labeledDescriptors = knownData.map(person =>
      new faceapi.LabeledFaceDescriptors(
        person.label,
        [new Float32Array(person.descriptors)]
      )
    );
    faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);
    statusEl.textContent = "✅ Models ready! Click Start.";
    startBtn.disabled = false;
  }

  async function startCamera() {
    const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
    video.srcObject = stream;
    detectLoop();
  }

  async function detectLoop() {
    const displaySize = { width: video.width, height: video.height };
    const canvas = faceapi.createCanvasFromMedia(video);
    document.body.append(canvas);
    faceapi.matchDimensions(canvas, displaySize);

    setInterval(async () => {
      const detections = await faceapi
        .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptors();

      const resized = faceapi.resizeResults(detections, displaySize);
      canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);

      resized.forEach(detection => {
        const bestMatch = faceMatcher.findBestMatch(detection.descriptor);
        const box = detection.detection.box;
        const text = bestMatch.label === "unknown"
          ? "❌ Unauthorized"
          : "✅ " + bestMatch.label;
        const drawBox = new faceapi.draw.DrawBox(box, { label: text });
        drawBox.draw(canvas);
      });
    }, 300);
  }

  startBtn.addEventListener('click', startCamera);
  loadModels();
  </script>
</body>
</html>
