<!DOCTYPE html>
<html>
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Face Recognition System</title>
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      padding: 10px;
    }
    video, canvas {
      border: 1px solid #ccc;
      border-radius: 8px;
      margin-top: 10px;
    }
    #status {
      margin-bottom: 10px;
      font-weight: bold;
    }
  </style>
</head>
<body>
  <h3>Face Recognition System</h3>
  <div id="status">‚è≥ Loading system...</div>
 
  <input type="text" id="employeeId" placeholder="Enter Employee ID" required><br>
  <input type="text" id="fullName" placeholder="Enter Full Name" required><br>
  <button id="start" disabled>Start Camera</button><br><br>
 
  <video id="video" width="320" height="240" autoplay muted></video>
  <canvas id="overlay" width="320" height="240"></canvas>

<script>
  const statusEl = document.getElementById("status");
  const startBtn = document.getElementById("start");
  const video = document.getElementById("video");
  const canvas = document.getElementById("overlay");
  const ctx = canvas.getContext("2d");

  let labeledDescriptors = [];
  const MODEL_URL = "./model/weights/";   // make sure this folder exists
  const IMAGE_PATH = "./images/";         // make sure this folder exists

  // Stability counters
  let recognizedCount = 0;
  let noFaceCount = 0;
  let mismatchCount = 0;
  let currentStatus = "";

  // ‚úÖ Send recognized data to Google Sheet
  async function sendToSheet(employeeId, fullName, imageLink) {
    const SHEET_URL = "https://script.google.com/macros/s/AKfycbzi6clCEtiZp6qfcN0mvAuxHv0pp4gRy6reoIcVz8e8Ui1he-cul9ne8DR2wfoPx0ED/exec";
    const status = "Face recognized";
    const source = "Face Recognition System";

    const params = new URLSearchParams({
      employeeId,
      name: fullName,
      imageLink,
      status,
      source
    });

    try {
      await fetch(`${SHEET_URL}?${params.toString()}`);
      console.log("‚úÖ Data sent to Google Sheet");
    } catch (err) {
      console.error("‚ùå Error sending to sheet:", err);
    }
  }

  // ‚úÖ Load face-api.js models
  async function loadModels() {
    try {
      statusEl.textContent = "‚è≥ Loading models...";
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL)
      ]);
      statusEl.textContent = "‚úÖ Models loaded ‚Äî enter details and start camera.";
      startBtn.disabled = false; // enable button after models load
    } catch (err) {
      statusEl.textContent = "‚ùå Model load error: " + err.message;
      console.error(err);
    }
  }

  // ‚úÖ Load one stored face image based on full name
  async function loadLabeledImage(fullName) {
    labeledDescriptors = [];
    const fileName = fullName.trim();
    const imgUrl = `${IMAGE_PATH}${fileName}.jpg`;
    try {
      const img = await faceapi.fetchImage(imgUrl);
      const detection = await faceapi
        .detectSingleFace(img, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptor();
      if (detection) {
        labeledDescriptors.push(new faceapi.LabeledFaceDescriptors(fullName, [detection.descriptor]));
        console.log(`‚úÖ Loaded stored photo for: ${fullName}`);
      } else {
        alert(`‚ö†Ô∏è No face detected in stored photo for ${fullName}`);
      }
    } catch (err) {
      alert(`‚ùå Could not load image for "${fullName}". Ensure ${fileName}.jpg exists in /images.`);
      console.error(err);
    }
  }

  // ‚úÖ Helper function to show stable messages
  function updateStatus(newStatus) {
    if (currentStatus !== newStatus) {
      statusEl.textContent = newStatus;
      currentStatus = newStatus;
      console.log("üì¢ Status changed:", newStatus);
    }
  }

  // ‚úÖ Start camera and detect face
  startBtn.onclick = async () => {
    const employeeId = document.getElementById("employeeId").value.trim();
    const fullName = document.getElementById("fullName").value.trim();

    if (!employeeId || !fullName) {
      alert("Please enter both Employee ID and Full Name before starting.");
      return;
    }

    await loadLabeledImage(fullName);
    if (labeledDescriptors.length === 0) {
      alert("No labeled face loaded! Check image name or path.");
      return;
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      await video.play();
      updateStatus("üé• Camera started ‚Äî scanning face...");

      const faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);

      setInterval(async () => {
        const detections = await faceapi
          .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks()
          .withFaceDescriptors();

        ctx.clearRect(0, 0, canvas.width, canvas.height);
        faceapi.matchDimensions(canvas, { width: video.width, height: video.height });
        const resized = faceapi.resizeResults(detections, {
          width: video.width,
          height: video.height
        });

        // --- Stability logic ---
        if (resized.length === 0) {
          noFaceCount++;
          recognizedCount = mismatchCount = 0;
          if (noFaceCount >= 3) updateStatus("‚ùå No face detected.");
          return;
        }

        const results = resized.map(d => faceMatcher.findBestMatch(d.descriptor));

        results.forEach(async (result, i) => {
          const box = resized[i].detection.box;
          const label = result.label;
          new faceapi.draw.DrawBox(box, { label }).draw(canvas);

          // ‚úÖ If match found
          if (label !== "unknown" && label === fullName) {
            recognizedCount++;
            mismatchCount = noFaceCount = 0;
            if (recognizedCount >= 3) {
              updateStatus(`‚úÖ Face recognized: ${fullName}`);
              const imageLink = `${location.origin}/images/${fullName}.jpg`;
              await sendToSheet(employeeId, fullName, imageLink);

              // üîπ Stop camera and redirect after 1 second
              const tracks = video.srcObject.getTracks();
              tracks.forEach(track => track.stop());
              setTimeout(() => {
                window.location.href = "./success.html";
              }, 1000);
            }
          } else {
            // ‚ùå No match found
            mismatchCount++;
            recognizedCount = noFaceCount = 0;
            if (mismatchCount >= 3) {
              updateStatus(`‚ùå Face does not match stored photo for "${fullName}"`);
              const tracks = video.srcObject.getTracks();
              tracks.forEach(track => track.stop());
              setTimeout(() => {
                window.location.href = "./fail.html";
              }, 1000);
            }
          }
        });
      }, 800); // Runs every 0.8s
    } catch (err) {
      updateStatus("‚ö†Ô∏è Camera error: " + err.message);
      console.error(err);
    }
  };

  window.addEventListener("load", loadModels);
</script>

</body>
</html>


