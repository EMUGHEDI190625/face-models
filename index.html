
<!DOCTYPE html>
<html>
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Face Recognition System</title>

  <!-- Load face-api.js -->
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

  <style>
    body { font-family: Arial, sans-serif; text-align: center; padding: 10px; }
    video, canvas { border: 1px solid #ccc; border-radius: 8px; margin-top: 10px; }
    #status { margin-bottom: 10px; font-weight: bold; }
  </style>
</head>
<body>
  <h3>Face Recognition System</h3>
  <div id="status">Loading face-api.js...</div>

  <input type="text" id="employeeId" placeholder="Enter Employee ID" required><br>
  <input type="text" id="fullName" placeholder="Enter Full Name" required><br>
  <button id="start" disabled>Start Camera</button><br><br>

  <video id="video" width="320" height="240" autoplay muted></video>
  <canvas id="overlay" width="320" height="240"></canvas>

<script>
const statusEl = document.getElementById("status");
const startBtn = document.getElementById("start");
const video = document.getElementById("video");
const canvas = document.getElementById("overlay");
const ctx = canvas.getContext("2d");
let labeledDescriptors = [];

// ‚úÖ Path to your model and image folders
const MODEL_URL = "./model/";
const IMAGE_PATH = "./images/"; // Make sure your images are here

// Load face-api.js models first
async function loadModels() {
  try {
    statusEl.textContent = "‚è≥ Loading models...";

    await Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
      faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
      faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL)
    ]);

    statusEl.textContent = "‚úÖ Models loaded ‚Äî enter your name and start camera.";
    startBtn.disabled = false;
  } catch (err) {
    statusEl.textContent = "‚ùå Model load error: " + err.message;
    console.error(err);
  }
}

// Load the user's image based on the name typed
async function loadLabeledImage(fullName) {
  labeledDescriptors = [];
  const imageName = fullName.trim().toLowerCase(); // safer naming
  const imgUrl = `${IMAGE_PATH}${imageName}.jpg`;

  try {
    const img = await faceapi.fetchImage(imgUrl);
    const detections = await faceapi
      .detectSingleFace(img, new faceapi.TinyFaceDetectorOptions())
      .withFaceLandmarks()
      .withFaceDescriptor();

    if (detections) {
      labeledDescriptors.push(
        new faceapi.LabeledFaceDescriptors(fullName, [detections.descriptor])
      );
      console.log(`‚úÖ Loaded ${fullName}'s face`);
    } else {
      console.warn(`‚ö†Ô∏è No face detected for ${fullName}`);
    }
  } catch (err) {
    console.error(`Error loading image for ${fullName}:`, err);
    alert(`‚ùå Could not load image for "${fullName}". Make sure ${imageName}.jpg exists in /images folder.`);
  }
}

// Start camera and recognition
startBtn.onclick = async () => {
  const fullName = document.getElementById("fullName").value.trim();
  const employeeId = document.getElementById("employeeId").value.trim();

  if (!fullName || !employeeId) {
    alert("Please enter both Employee ID and Full Name before starting.");
    return;
  }

  await loadLabeledImage(fullName);
  if (!labeledDescriptors || labeledDescriptors.length === 0) {
    alert("No labeled face loaded! Check image name or path.");
    return;
  }

  try {
    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
    video.srcObject = stream;
    await video.play();
    statusEl.textContent = "üé• Camera started ‚Äî detecting faces...";

    const faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);

    setInterval(async () => {
      const detections = await faceapi
        .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptors();

      ctx.clearRect(0, 0, canvas.width, canvas.height);
      faceapi.matchDimensions(canvas, { width: video.width, height: video.height });

      const resized = faceapi.resizeResults(detections, {
        width: video.width,
        height: video.height
      });

      const results = resized.map(d => faceMatcher.findBestMatch(d.descriptor));
      results.forEach((result, i) => {
        const box = resized[i].detection.box;
        const drawBox = new faceapi.draw.DrawBox(box, { label: result.toString() });
        drawBox.draw(canvas);
      });
    }, 1000);
  } catch (err) {
    statusEl.textContent = "‚ö†Ô∏è Camera error: " + err.message;
    console.error(err);
  }
};

window.addEventListener("load", loadModels);
</script>
</body>
</html>
